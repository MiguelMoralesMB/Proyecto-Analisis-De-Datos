import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import MinMaxScaler

# =============================================================================
# CONFIGURACIÃ“N
# =============================================================================
ARCHIVO_CSV = "Earthquakes_USGS.csv"
ARCHIVO_PARQUET = "terremotos_limpios.parquet"

def optimizar_memoria(df):
    """
    Reduce el uso de memoria convirtiendo tipos de datos.
    float64 -> float32
    int64 -> int32
    object -> category (si hay pocos valores Ãºnicos)
    """
    start_mem = df.memory_usage().sum() / 1024**2
    print(f"   Memoria antes de optimizar: {start_mem:.2f} MB")
    
    for col in df.columns:
        col_type = df[col].dtype
        
        if col_type != object:
            # Optimizar NÃºmeros
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
            else:
                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
        else:
            # Optimizar Texto a CategorÃ­a si hay pocos valores Ãºnicos (menos del 50%)
            num_unique = len(df[col].unique())
            num_total = len(df[col])
            if num_unique / num_total < 0.5:
                df[col] = df[col].astype('category')

    end_mem = df.memory_usage().sum() / 1024**2
    print(f"   Memoria despuÃ©s de optimizar: {end_mem:.2f} MB")
    return df

# =============================================================================
# LÃ“GICA DE CARGA INTELIGENTE
# =============================================================================

if os.path.exists(ARCHIVO_PARQUET):
    # --- CAMINO RÃPIDO ---
    print(f"ðŸš€ Archivo optimizado detectado: '{ARCHIVO_PARQUET}'")
    print("Cargando datos procesados (esto serÃ¡ rÃ¡pido)...")
    terremotos = pd.read_parquet(ARCHIVO_PARQUET)
    print("âœ… Carga completada.")

else:
    # --- CAMINO LENTO (Solo la primera vez) ---
    print(f"âš ï¸ Archivo optimizado no encontrado.")
    print(f"Cargando '{ARCHIVO_CSV}' (esto tomarÃ¡ tiempo, paciencia)...")
    
    # 1. CARGA
    # Usamos low_memory=False para evitar DtypeWarning y errores, aunque use mÃ¡s RAM
    try:
        terremotos = pd.read_csv(ARCHIVO_CSV, low_memory=False)
    except Exception as e:
        print(f"Error crÃ­tico al cargar: {e}")
        exit()

    print("âœ… CSV Cargado. Iniciando limpieza y optimizaciÃ³n...")

    # 2. OPTIMIZACIÃ“N DE MEMORIA PARA RAM 16gb
    terremotos = optimizar_memoria(terremotos)

    # 3. LIMPIEZA DE DUPLICADOS
    filas_antes = len(terremotos)
    terremotos.drop_duplicates(inplace=True)
    print(f"   Duplicados eliminados: {filas_antes - len(terremotos)}")

    # 4. TRATAMIENTO DE NULOS
    # Estrategia: 
    # - Eliminar filas si faltan datos crÃ­ticos (Ej: Magnitud o UbicaciÃ³n)
    # - Rellenar datos secundarios con la mediana o 'Desconocido'
    
    # A. Eliminar nulos crÃ­ticos (Ajusta 'mag' segÃºn tus columnas reales)
    if 'mag' in terremotos.columns:
        terremotos.dropna(subset=['mag', 'latitude', 'longitude'], inplace=True)
    
    # B. Imputar nulos numÃ©ricos restantes con la Mediana
    cols_numericas = terremotos.select_dtypes(include=['float32', 'int32', 'float64']).columns
    for col in cols_numericas:
        terremotos[col] = terremotos[col].fillna(terremotos[col].median())

    # C. Imputar nulos de texto con 'Desconocido'
    cols_texto = terremotos.select_dtypes(include=['object', 'category']).columns
    for col in cols_texto:
        if terremotos[col].dtype.name == 'category':
            # AÃ±adir la categorÃ­a antes de llenar
            if 'Desconocido' not in terremotos[col].cat.categories:
                terremotos[col] = terremotos[col].cat.add_categories('Desconocido')
            terremotos[col] = terremotos[col].fillna('Desconocido')
        else:
            terremotos[col] = terremotos[col].fillna('Desconocido')

    # 5. FORMATOS
    # Convertir columna de tiempo a datetime
    if 'time' in terremotos.columns:
        terremotos['time'] = pd.to_datetime(terremotos['time'], errors='coerce')

    # Normalizar texto (MinÃºsculas y sin espacios extra)
    if 'place' in terremotos.columns:
        terremotos['place'] = terremotos['place'].astype(str).str.lower().str.strip()

    # 6. NORMALIZACIÃ“N (Min-Max Scaling)
    # Solo normalizamos columnas Ãºtiles para modelos (Ej: profundidad y magnitud)
    cols_a_normalizar = ['depth', 'mag'] # AsegÃºrate que existan
    cols_existentes = [c for c in cols_a_normalizar if c in terremotos.columns]
    
    if cols_existentes:
        scaler = MinMaxScaler()
        # Creamos nuevas columnas normalizadas para no perder las originales
        nombres_nuevos = [f"{c}_norm" for c in cols_existentes]
        terremotos[nombres_nuevos] = scaler.fit_transform(terremotos[cols_existentes])
        print("   NormalizaciÃ³n aplicada a: ", cols_existentes)

    # 7. GUARDAR PROGRESO
    print("ðŸ’¾ Guardando resultado en formato Parquet...")
    terremotos.to_parquet(ARCHIVO_PARQUET, index=False)
    print("âœ… Â¡Proceso completado y guardado! La prÃ³xima ejecuciÃ³n serÃ¡ instantÃ¡nea.")

# =============================================================================
# ZONA DE TRABAJO Y ANÃLISIS
# =============================================================================

print("\n" + "="*40)
print("INFORMACIÃ“N DEL DATASET LISTO")
print("="*40)
print(terremotos.info())
print("\nPrimeras 5 filas:")
print(terremotos.head())

# --- TU CÃ“DIGO DE MINERÃA VA AQUÃ ABAJO ---